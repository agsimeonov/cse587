# CSE 587 - Data-Intensive Computing

Data-intensive computing deals with storage models, application architectures, middleware, and programming models and tools for large-scale data analytics. In particular we study approaches that address challenges in managing and utilizing ultra-scale data and the methods for transforming voluminous datasets (big data) into discoveries and intelligence for human understanding and decision making. Topics include: intelligent representation of data, approaches discovering intelligence in data, data-driven computing, storage requirements of big data, organization of big data repositories such as Google File System (GFS), characteristics of Write-Once-Read-Many (WORM) data, data-intensive programming models such as MapReduce, fault-tolerance, privacy, security and performance, services-based cloud computing middleware, and scalable analytics and visualization. This course has four major goals: (i) understand data- intensive computing, that has been defined as the fourth paradigm for Sciences by the late Jim Grey, (ii) study, design and develop solutions using data-intensive computing models such as MapReduce, (iii) predictive analytics and visualization using packages such as R and Google analytics and (iv) focus on methods for scalability using the cloud computing infrastructures such as Google App Engine (GAE), and Amazon Elastic Compute Cloud (EC2).
